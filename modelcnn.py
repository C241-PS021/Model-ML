# -*- coding: utf-8 -*-
"""ModelCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nB4z1kANINDZ_2j-8aR1A-NqWhptTrqG
"""

# Import libraries
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import os
import zipfile

from google.colab import drive
drive.mount("/content/drive")

# read dataset
zip_file = '/content/drive/MyDrive/Fruit_Vegetables/Dataset/dataset.zip'
with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall('data')

import os
import shutil
import random

def split_data(SOURCE='', TRAINING='', TEST='', TRAIN_SPLIT=0.8): #  VALIDATION='', VAL_SPLIT=0.10):
    classes = os.listdir(SOURCE)
    for class_name in classes:
        class_dir = os.path.join(SOURCE, class_name)
        images = os.listdir(class_dir)
        random.shuffle(images)

        train_size = int(len(images) * TRAIN_SPLIT)
        #val_size = int(len(images) * VAL_SPLIT)

        train_images = images[:train_size]
        #val_images = images[train_size:train_size + val_size]
        test_images = images[train_size:] # train_size + val_size

        train_class_dir = os.path.join(TRAINING, class_name)
        #val_class_dir = os.path.join(VALIDATION, class_name)
        test_class_dir = os.path.join(TEST, class_name)

        os.makedirs(train_class_dir, exist_ok=True)
        #os.makedirs(val_class_dir, exist_ok=True)
        os.makedirs(test_class_dir, exist_ok=True)

        for img in train_images:
            src = os.path.join(class_dir, img)
            dst = os.path.join(train_class_dir, img)
            shutil.copy(src, dst)

        # for img in val_images:
        #     src = os.path.join(class_dir, img)
        #     dst = os.path.join(val_class_dir, img)
        #     shutil.copy(src, dst)

        for img in test_images:
            src = os.path.join(class_dir, img)
            dst = os.path.join(test_class_dir, img)
            shutil.copy(src, dst)

# Define the base directory
base_dir = 'data/Fruits_Vegetables_Dataset(12000)'

# Define the new directories
new_base_dir = 'data/split_dataset'
train_dir = os.path.join(new_base_dir, 'train')
# validation_dir = os.path.join(new_base_dir, 'validation')
test_dir = os.path.join(new_base_dir, 'test')

# Create directories if they don't exist
os.makedirs(train_dir, exist_ok=True)
# os.makedirs(validation_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)

# Define the source directories for fruits and vegetables
fruit_source_dir = os.path.join(base_dir, 'Fruits')
vegetable_source_dir = os.path.join(base_dir, 'Vegetables')

# Split and copy images for fruits and vegetables
split_data(SOURCE=fruit_source_dir, TRAINING=train_dir, TEST=test_dir, TRAIN_SPLIT=0.8) # VALIDATION=validation_dir,  VAL_SPLIT=0.15
split_data(SOURCE=vegetable_source_dir, TRAINING=train_dir, TEST=test_dir, TRAIN_SPLIT=0.8) # VALIDATION=validation_dir,  VAL_SPLIT=0.15

# Function to count images in a directory
def count_images(directory):
    count = 0
    for root, dirs, files in os.walk(directory):
        count += len(files)
    return count

def count_images_per_class(directory):
    class_counts = {}
    for class_name in os.listdir(directory):
        class_dir = os.path.join(directory, class_name)
        if os.path.isdir(class_dir):
            class_counts[class_name] = len(os.listdir(class_dir))
    return class_counts

# Print the number of images in each directory
print('Number of images in train directory:', count_images(train_dir))
#print('Number of images in validation directory:', count_images(validation_dir))
print('Number of images in test directory:', count_images(test_dir))

# Print the number of images in each class for train, validation, and test directories
print('Training data per class:', count_images_per_class(train_dir))
#print('Validation data per class:', count_images_per_class(validation_dir))
print('Test data per class:', count_images_per_class(test_dir))

# Preview images in each class (first 10 images)
def preview_images(directory, class_name):
    class_dir = os.path.join(directory, class_name)
    if os.path.isdir(class_dir):
        images = os.listdir(class_dir)
        print(f'{class_name} files:', images[:10])

# Example of previewing images
for class_name in os.listdir(train_dir):
    preview_images(train_dir, class_name)
# for class_name in os.listdir(validation_dir):
#     preview_images(validation_dir, class_name)
# for class_name in os.listdir(test_dir):
#     preview_images(test_dir, class_name)

# Augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.6,
    horizontal_flip=True,
    vertical_flip=False,
    fill_mode='nearest',
    validation_split=0.2
)

validation_datagen = ImageDataGenerator(rescale=1./255)

from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

train_fresh_dir = os.path.join('data/split_dataset/train/FreshBanana')
preview_dir = 'data/preview'
os.makedirs(preview_dir, exist_ok=True)

# Load an image from the training directory
path_aug = os.path.join(train_fresh_dir, os.listdir(train_fresh_dir)[-1])
img_augmentation = image.load_img(path_aug)
x_aug = image.img_to_array(img_augmentation)
x_aug = x_aug.reshape((1,) + x_aug.shape)

# Generate augmented images and save to preview directory
i = 0
for batch in train_datagen.flow(x_aug, batch_size=1, save_to_dir=preview_dir, save_prefix='fruit', save_format='jpg'):
    i += 1
    if i >= 20:
        break

# List the generated images
preview_img = os.listdir(preview_dir)

# Plot the augmented images
plt.figure(figsize=(15, 15))
for n in range(len(preview_img)):
    plt.subplot((len(preview_img)//4)+0, 4, n+1)
    plt.subplots_adjust(wspace=0.1, hspace = 0.2)
    plt.imshow(image.load_img(os.path.join(preview_dir, preview_img[n]),
                              color_mode="rgb",
                              target_size=(150, 150),
                              interpolation="nearest"))
    plt.axis('off')
plt.show()

# Clean up preview directory
for fn in preview_img:
    os.remove(os.path.join(preview_dir, fn))

# Create image generators for training, validation, and test datasets
base_dir = 'data/split_dataset'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'test')
#test_dir = os.path.join(base_dir, 'test')

# Define batch size and target size
batch_size = 32
target_size = (150, 150)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical'
)

# test_generator = test_datagen.flow_from_directory(
#     test_dir,
#     target_size=target_size,
#     batch_size=batch_size,
#     class_mode='categorical'
# )

# define callbacks
class Callbacks(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        if logs.get('accuracy') >= 0.90:
            print("\nAccuracy model has reached 90%, stop traning")
            self.model.stop_training = True

callbacks = [Callbacks()]

# Create Model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(20, activation='sigmoid')  # Output layer for binary classification
])

# Compile Model
model.compile(
    loss='categorical_crossentropy',  # Loss function for binary classification
    optimizer='adam',
    metrics=['accuracy']
)
model.summary()

# Train Model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=500,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size,
    callbacks=callbacks
)

# Memvisualisasikan Akurasi
plt.figure(figsize=(14, 5))

# Akurasi
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

import numpy as np
from google.colab import files
from tensorflow.keras.utils import load_img, img_to_array

uploaded = files.upload()

# set images size
img_width, img_height = 150, 150

for fn in uploaded.keys():
    # proses the images
    path = fn
    img = load_img(path, target_size=(img_width, img_height))
    x = img_to_array(img)
    x = np.expand_dims(x, axis=0)

    # merge images if more than one
    images = np.vstack([x])

    # predict images
    classes = model.predict(images, batch_size=10)

    # show the predict
    print(f"Filename: {fn}")
    print(f"Prediction: {classes}")

